



\documentclass[journal]{IEEEtran}

% *** CITATION PACKAGES ***
%
\usepackage{cite}

% *** GRAPHICS RELATED PACKAGES ***
%
\ifCLASSINFOpdf
  \usepackage[pdftex]{graphicx}
  \graphicspath{{../pdf/}{../jpeg/}}
  \DeclareGraphicsExtensions{.pdf,.jpeg,.png}
\else
  \usepackage[dvips]{graphicx}
  \graphicspath{{../eps/}}
  \DeclareGraphicsExtensions{.eps}
\fi
\usepackage{amsmath}
\interdisplaylinepenalty=2500

\usepackage{array}
\usepackage{fixltx2e}
\usepackage{stfloats}
\usepackage{url}
% Basically, \url{my_url_here}.


% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}


\begin{document}
% Definition of blocks:

\title{EEG and MEG Inversion Using Convolutional and Recurrent Neural Networks}
%
%
% author names and IEEE memberships
% note positions of commas and nonbreaking spaces ( ~ ) LaTeX will not break
% a structure at a ~ so this keeps an author's name from being broken across
% two lines.
% use \thanks{} to gain access to the first footnote area
% a separate \thanks must be used for each paragraph as LaTeX2e's \thanks
% was not built to handle multiple paragraphs
%

\author{Joaquin~J.~Casanova,~\IEEEmembership{Member,~IEEE,}
        Zachary~D.~Stoecker-Sylvia,~\IEEEmembership{Member,~IEEE,}
        Ryan~Miyamoto,~\IEEEmembership{Member,~IEEE,}
        and~Jenshan~Lin,~\IEEEmembership{Fellow,~IEEE}% <-this % stops a space
\thanks{J. Casanova and J. Lin are with the Department
of Electrical and Computer Engineering, University of Florida, Gainesville,
FL, 32611 USA e-mail: jcasa@ufl.edu}% <-this % stops a space
\thanks{R. Miyamoto and Z. Stoecker-Sylvia are with Oceanit.}% <-this % stops a space

\thanks{Manuscript received }}

% The paper headers
\markboth{Transaction on Neural Systems and Rehabilitation Engineering,~Vol.~XX, No. YY}%
{Casanova \MakeLowercase{\textit{et al.}}: EEG and MEG Dipole Localization Using Convolutional and Recurrent Neural Networks}
\maketitle

\begin{abstract}

  Real-time localzation of neuronal activity has a number of uses, including brain-computer interfaces and medical diagnostics. Generally, this is done by taking measurements of the brain's magnetic and electric fields (magnetoencephalography [MEG] and electroencephalography [EEG]), and inverting the measurements. Most approaches are physically-based, and attempt to find the best estimate of the lead-field matrix, which relates the dipole activation to the field strength by minimizing the error of an estimate. To date, most approaches using the lead-field matrix are complicated and too slow in real time, aimed primarily at elucidating brain structural functional relationships from experimental data. We propose a new technique in which the location of peak neuronal current is estimated by treating EEG and MEG as a two-channel image, or time-series of images, which is processed by a neural network which returns the location of the dipole of peak magnitude. Four archtectures are tested: 2-layer perceptron, convolutional neural network (CNN), recurrent neural network (RNN), and CNN feeding RNN. In the absence of true measures of neuronal activity, we used two publicly available MEG/EEG datasets, and treated the estimates of the traditional minimum-norm estimate (MNE) as true estimates. We test the four variations of the network architecture, and in the best case (CNN only), we achieve test dataset errors (RMSE of max dipole location) of between XX and YY mm.
  
\end{abstract}

% Note that keywords are not normally used for peerreview papers.
\begin{IEEEkeywords}
EEG, MEG, Localization, Neural networks.
\end{IEEEkeywords}






% For peer review papers, you can put extra information on the cover
% page as needed:
% \ifCLASSOPTIONpeerreview
% \begin{center} \bfseries EDICS Category: 3-BBND \end{center}
% \fi
%
% For peerreview papers, this IEEEtran command inserts a page break and
% creates the second title. It will be ignored for other modes.
\IEEEpeerreviewmaketitle



\section{Introduction}

\IEEEPARstart{T}{here} is a great need for interpretation of brain signals for both use in control of devices, for prosthetics, for example, or for disease diagnostics. Magnetoencephalography (MEG), the measurement of the brain's magnetic field, is typically done using cryogenic superconducting quantum interference devices (SQUID) on a dense grid surrounding the skull, and has been used in brain-computer interfaces \cite{mellinger2007meg}. Additionally, electroencephalography (EEG), is also used for BCI as well as medical diagnostics and study of brain stucture and function \cite{da2008impact}. Particularly for the latter, there is great utility in using the external measurements of MEG and EEG to determine which parts of the brain are most electrically active, a problem know as localization or inversion. Functional magnetic resonance imaging (fMRI) can be used but instead measures blood flow, and is thus not a direct measurement of electrical activity \cite{sharon2007advantage}.


Classically, MEG/EEG inversion has followed one of a few approaches, with incremental enhancements as sophistication and computational power has increased. \cite{grech2008review} provides an excellent review of techniques. \cite{mosher1992multiple} established the oroignal framework of the dipole in a sphere model, in which a lead-field matrix based on magnetostatic and electrostatic equations, and the positions of dipoles, transforms a vector of dipole magnitudes into a vector of magnetic flux and electric potential at sensor locations. The problem of localization becomes a problem of finding the locations and magnitudes of dipoles that minimize the square error of predicted versus observed fields. Using this formalism and a finite-element model, \cite{buchner1997inverse} localized dipoles from MEG data. \cite{galka2004solution} used Kalman filtering to solve the dynamical inverse problem. Thesignal-space separation method transforms the data into basis functions in signal space to better filter background noise sources \cite{taulu2005applications}. Beamformer techniques have also been applied for MEG/EEG inversion \cite{sekihara2001reconstructing}. More recently, EEG has been inverted using artificial neural networks \cite{van2000eeg}.


Neural networks have proven an important tool for accurate predictions from noisy and large datasets. A recent technique is convolutional neural networks, in which image inputs are convolved with weighted kernels \cite{lecun1998gradient}. To treat time-series or sequences, recurrent neural networks, incorporating temporal feedback, have been developed, such as the long-short-term memory RNN \cite{hochreiter1997long}. CNN and RNN have been combined in \cite{venugopalan2014translating} to translate video sequences into text descriptions of the video.


Our proposed idea is to apply the combined CNN/RNN framework to sequences of MEG/EEG data, and predict the location of only the peak dipole. In this way we simplify the problem, and with approporiately trained networks, we could make quick predicts from data, possibly in real time. To demonstrate our technique, we use publicly available datasets, and use the dipole currents predicted by a well established technique (MNE) as the true value to which we compare our estimates and train our network \cite{gramfort2014mne}. Further, we investigate four variations of the network architecture (2-layer MLP, RNN, CNN, and CNN with RNN), to establish the advantages and disadvantages of each.

\section{Methods}

In this section, we describe our methodology, including datasets, preprocessing, and neural network architectures.

\subsubsection{Datasets}

To test our method, we used two multimodal datasets. Both were processed using the python-mne package \cite{gramfort2014mne}.

One dataset \cite{wakeman2015multi} consisted of 19 subjects presented with stimulus of famous, unfamiliar, or scrambled faces. There were 102 magnetometers, 204 planar gradiometers, and 70 electrodes, with 3 electrodes used for ocular and cardiac arifacts. We excluded gradiometers, as our study is to develop an inversion technique for use with our own MEG system, which only has the radial magnetometers. We considered one subject only (sub007) as that subject's MRI was the only one to segment properly into skin, skull, and cortex layers (an important feature for the inversion step). We used the data processing pipeline provided with the dataset here: \url{http://mne-tools.github.io/mne-biomag-group-demo/}. Sampling rate 1100 Hz 551 time points per trial, ico-4

The second dataset \cite{gramfort2013meg} is included with MNE. ... one ocular channel 59 eeg 102 mag oct-5 checkerboard patterns were presented into the left and right visual field, interspersed by tones to the left or right ear. 

\subsection{Preprocessing}
\subsection{Description of Neural Networks}
\url{tensorflow.com}
\cite{kingma2014adam}

Adam: A method for stochastic optimization

\begin{figure*}[!t]
\centering
\includegraphics[width=7in]{cnnrnn}
% where an .eps filename suffix will be assumed under latex, 
% and a .pdf suffix will be assumed for pdflatex; or what has been declared
% via \DeclareGraphicsExtensions.
\caption{Block diagram of CNN+RNN neural network.}
\label{fig_cnnrnn}
\end{figure*}
\begin{figure*}[!t]
\centering
\includegraphics[width=7in]{cnn}
% where an .eps filename suffix will be assumed under latex, 
% and a .pdf suffix will be assumed for pdflatex; or what has been declared
% via \DeclareGraphicsExtensions.
\caption{Block diagram of CNN neural network.}
\label{fig_cnn}
\end{figure*}
\begin{figure*}[!t]
\centering
\includegraphics[width=7in]{rnn}
% where an .eps filename suffix will be assumed under latex, 
% and a .pdf suffix will be assumed for pdflatex; or what has been declared
% via \DeclareGraphicsExtensions.
\caption{Block diagram of RNN neural network.}
\label{fig_rnn}
\end{figure*}
\begin{figure*}[!t]
\centering
\includegraphics[width=7in]{mlp}
% where an .eps filename suffix will be assumed under latex, 
% and a .pdf suffix will be assumed for pdflatex; or what has been declared
% via \DeclareGraphicsExtensions.
\caption{Block diagram of MLP neural network.}
\label{fig_mlp}
\end{figure*}

Subsection text here.

% needed in second column of first page if using \IEEEpubid
%\IEEEpubidadjcol
\subsection{Hyperparameters}

\subsection{Training and testing}
\section{Results}

\begin{figure*}[!t]
\centering
\includegraphics[width=7in]{aud1}
% where an .eps filename suffix will be assumed under latex, 
% and a .pdf suffix will be assumed for pdflatex; or what has been declared
% via \DeclareGraphicsExtensions.
\caption{Training/validation results for auditory stimulus dataset (1 dipole).}
\label{fig_aud}
\end{figure*}

\begin{figure*}[!t]
\centering
\includegraphics[width=7in]{faces1}
% where an .eps filename suffix will be assumed under latex, 
% and a .pdf suffix will be assumed for pdflatex; or what has been declared
% via \DeclareGraphicsExtensions.
\caption{Training/validation results for faces stimulus dataset (1 dipole).}
\label{fig_faces}
\end{figure*}

\begin{figure*}[!t]
\centering
\includegraphics[width=7in]{aud10}
% where an .eps filename suffix will be assumed under latex, 
% and a .pdf suffix will be assumed for pdflatex; or what has been declared
% via \DeclareGraphicsExtensions.
\caption{Training/validation results for auditory stimulus dataset (best of 10 dipoles).}
\label{fig_aud10}
\end{figure*}

\begin{figure*}[!t]
\centering
\includegraphics[width=7in]{faces10}
% where an .eps filename suffix will be assumed under latex, 
% and a .pdf suffix will be assumed for pdflatex; or what has been declared
% via \DeclareGraphicsExtensions.
\caption{Training/validation results for faces stimulus dataset (best of 10 dipoles).}
\label{fig_faces10}
\end{figure*}

\begin{figure*}[!t]
\centering
\includegraphics[width=7in]{aud100}
% where an .eps filename suffix will be assumed under latex, 
% and a .pdf suffix will be assumed for pdflatex; or what has been declared
% via \DeclareGraphicsExtensions.
\caption{Training/validation results for auditory stimulus dataset (best of 100 dipole).}
\label{fig_aud100}
\end{figure*}

\begin{figure*}[!t]
\centering
\includegraphics[width=7in]{faces100}
% where an .eps filename suffix will be assumed under latex, 
% and a .pdf suffix will be assumed for pdflatex; or what has been declared
% via \DeclareGraphicsExtensions.
\caption{Training/validation results for faces stimulus dataset (best of 100 dipoles).}
\label{fig_faces100}
\end{figure*}
\section{Conclusion}
The conclusion goes here.


% use section* for acknowledgment
\section*{Acknowledgment}


The authors would like to thank...



% references section

\bibliographystyle{IEEEtran}
\bibliography{./casanova_ieee}
%\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{mshell}}]{Michael Shell}
% or if you just want to reserve a space for a photo:

\begin{IEEEbiography}{}
\end{IEEEbiography}

% if you will not have a photo at all:
\begin{IEEEbiographynophoto}{}
\end{IEEEbiographynophoto}

% insert where needed to balance the two columns on the last page with
% biographies
%\newpage

\begin{IEEEbiographynophoto}{Jane Doe}
Biography text here.
\end{IEEEbiographynophoto}

% You can push biographies down or up by placing
% a \vfill before or after them. The appropriate
% use of \vfill depends on what kind of text is
% on the last page and whether or not the columns
% are being equalized.

%\vfill

% Can be used to pull up biographies so that the bottom of the last one
% is flush with the other column.
%\enlargethispage{-5in}



% that's all folks
\end{document}


\grid
